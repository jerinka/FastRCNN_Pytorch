{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4ef2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "colab=False #True: if in colab, Flase: if in local (pls change accordinngly!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1663198",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1622327682662,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "b1663198",
    "outputId": "e45b1691-04b8-4b36-f79f-04918a93efee"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "D20ZQ6ffNYbO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1622327683215,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "D20ZQ6ffNYbO",
    "outputId": "442ec858-201b-4294-eefc-dadf01edf284"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/skycam/sample_projs/FRCNN/delivered/FastRCNN_Traffic'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if colab:\n",
    "    #Add a shortcut of project folder to your drive's home for this to work\n",
    "    !ls '/content/drive/MyDrive/Traffic'\n",
    "    root = '/content/drive/MyDrive/Traffic'\n",
    "else:\n",
    "    import os\n",
    "    root = os.getcwd()\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "slVAbHOsST1W",
   "metadata": {
    "id": "slVAbHOsST1W"
   },
   "outputs": [],
   "source": [
    "#!unzip \"/content/drive/MyDrive/Traffic/Traffic_FRCNN.zip\" -d \"/content/drive/MyDrive/Traffic/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NOxMjtlOSZOX",
   "metadata": {
    "id": "NOxMjtlOSZOX"
   },
   "source": [
    "Uncomment above line after putting zip file inside Traffic folder. Create another notebook and put above cells in it do this unzipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2y96vcQ-Ojqw",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1622327683218,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "2y96vcQ-Ojqw"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    import sys\n",
    "    sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "k-AB5b3nNHP2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2530,
     "status": "ok",
     "timestamp": 1622327685736,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "k-AB5b3nNHP2",
    "outputId": "b2ddb316-7a0b-472f-e0b6-b0e71d1b19c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aniso8601==8.1.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (8.1.0)\n",
      "Requirement already satisfied: ansi2html==1.6.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: arrow==0.17.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: asttokens==2.0.4 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: attrs==20.3.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (20.3.0)\n",
      "Requirement already satisfied: certifi==2020.12.5 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (2020.12.5)\n",
      "Requirement already satisfied: chardet==4.0.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: click==7.1.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (7.1.2)\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (0.10.0)\n",
      "Requirement already satisfied: Cython==0.29.21 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (0.29.21)\n",
      "Requirement already satisfied: executing==0.5.4 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (0.5.4)\n",
      "Requirement already satisfied: Flask==1.1.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (1.1.2)\n",
      "Requirement already satisfied: Flask-RESTful==0.3.8 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (0.3.8)\n",
      "Requirement already satisfied: idna==2.10 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 14)) (2.10)\n",
      "Requirement already satisfied: importlib-metadata==3.3.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (3.3.0)\n",
      "Requirement already satisfied: iniconfig==1.1.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (1.1.1)\n",
      "Requirement already satisfied: itsdangerous==1.1.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (1.1.0)\n",
      "Requirement already satisfied: Jinja2==2.11.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 18)) (2.11.2)\n",
      "Requirement already satisfied: kiwisolver==1.3.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 19)) (1.3.1)\n",
      "Requirement already satisfied: littleutils==0.2.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 20)) (0.2.2)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 21)) (1.1.1)\n",
      "Requirement already satisfied: matplotlib==3.3.3 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 22)) (3.3.3)\n",
      "Requirement already satisfied: numpy in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 23)) (1.19.5)\n",
      "Requirement already satisfied: nvidia-ml-py3==7.352.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 24)) (7.352.0)\n",
      "Requirement already satisfied: olefile==0.46 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 25)) (0.46)\n",
      "Requirement already satisfied: packaging==20.8 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 26)) (20.8)\n",
      "Requirement already satisfied: pandas in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 27)) (1.1.5)\n",
      "Requirement already satisfied: Pillow in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 28)) (8.1.2)\n",
      "Requirement already satisfied: pluggy==0.13.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 29)) (0.13.1)\n",
      "Requirement already satisfied: psutil==5.8.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 30)) (5.8.0)\n",
      "Requirement already satisfied: py==1.10.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 31)) (1.10.0)\n",
      "Requirement already satisfied: pycocotools==2.0.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 32)) (2.0.2)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 33)) (2.4.7)\n",
      "Requirement already satisfied: pytest==6.2.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 34)) (6.2.1)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 35)) (2.8.1)\n",
      "Requirement already satisfied: pytz==2020.5 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 36)) (2020.5)\n",
      "Requirement already satisfied: requests==2.25.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 37)) (2.25.1)\n",
      "Requirement already satisfied: six in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 38)) (1.15.0)\n",
      "Requirement already satisfied: sorcery==0.2.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 39)) (0.2.1)\n",
      "Requirement already satisfied: tabulate==0.8.7 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 40)) (0.8.7)\n",
      "Requirement already satisfied: termcolor==1.1.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 41)) (1.1.0)\n",
      "Requirement already satisfied: toml==0.10.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 42)) (0.10.2)\n",
      "Requirement already satisfied: torch==1.4.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 43)) (1.4.0)\n",
      "Requirement already satisfied: torchaudio in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 44)) (0.4.0)\n",
      "Requirement already satisfied: torchvision==0.5.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 45)) (0.5.0)\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 46)) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3==1.26.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 47)) (1.26.2)\n",
      "Requirement already satisfied: Werkzeug==1.0.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 48)) (1.0.1)\n",
      "Requirement already satisfied: wrapt==1.12.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 49)) (1.12.1)\n",
      "Requirement already satisfied: xmltodict==0.12.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 50)) (0.12.0)\n",
      "Requirement already satisfied: zipp==3.4.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 51)) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from pycocotools==2.0.2->-r requirements.txt (line 32)) (54.2.0)\n"
     ]
    }
   ],
   "source": [
    "if colab:\n",
    "    !pip3 install -r '/content/drive/MyDrive/Traffic/requirements.txt'\n",
    "else:\n",
    "    !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362e2393",
   "metadata": {
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1622327686294,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "362e2393"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utilities.data_utils.Dataset import FacialDataset, get_transform\n",
    "from utilities.utils import collate_fn\n",
    "from utilities.train_eval.engine import train_one_epoch, evaluate, get_model_result\n",
    "import glob\n",
    "\n",
    "import nvidia_smi # for python 3, you need nvidia-ml-py3 library\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31b021e",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1622327686295,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "c31b021e"
   },
   "outputs": [],
   "source": [
    "PATH = 'Weight.pth'\n",
    "\n",
    "output_image_folder = 'output'\n",
    "\n",
    "proj = 'sign' # 'sign','fabric' (put ur project name here)\n",
    "\n",
    "if proj == 'sign':\n",
    "    classes = ['warning', 'prohibitory', 'mandatory']\n",
    "elif proj == 'fabric':\n",
    "    classes = ['Hole', 'Line', 'Stain']\n",
    "else:\n",
    "    classes = ['bg']\n",
    "\n",
    "num_classes = len(classes)+1  # n class + background\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "num_epochs = 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b63ec7fa",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622327686295,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "b63ec7fa"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "nvidia_smi.nvmlInit()\n",
    "#handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "#info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "#print(\"Total memory:\", info.total)\n",
    "#print(\"Free memory:\", info.free)\n",
    "#print(\"Used memory:\", info.used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b9243f",
   "metadata": {
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1622327686800,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "44b9243f"
   },
   "outputs": [],
   "source": [
    "dataset_train = FacialDataset(root+'/data/train', get_transform(horizontal_flip=True),classes=classes)\n",
    "dataset_test = FacialDataset(root+'/data/test', get_transform(horizontal_flip=False),classes=classes)\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0,\n",
    "        collate_fn=collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=0,\n",
    "    collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e88219df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "1f070ccd6e734de2b967233201ba264f",
      "39f0d703e45740abb4808269b3c3da1a",
      "01e13365ef294ce9a03782c21bdab977",
      "1da9449b11624a5e847d8f9db04a1be2",
      "9d3963cb37194a538f667c2912fc5e50",
      "fae98b5c8a204731924b2f86a0ced1d8",
      "9148ee255b104e6791272c05c250f5f5",
      "54d6b5110a954b31977d857a5ce90e68"
     ]
    },
    "executionInfo": {
     "elapsed": 3380,
     "status": "ok",
     "timestamp": 1622327690179,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "e88219df",
    "outputId": "e1f7f402-1b92-43f6-f310-71cc65f133e6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a20d4ad",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1622327690181,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "8a20d4ad"
   },
   "outputs": [],
   "source": [
    "anchor_generator = AnchorGenerator(sizes=((32,), (24, ), (24, ), (16,), (8, )),\n",
    "                                        aspect_ratios=([1.0, 1.0, 1.0, 1.0], \n",
    "                                                     [0.8, 1.0, 1.0, 1.0], \n",
    "                                                     [1.0, 0.8, 1.0, 1.0],\n",
    "                                                     [1.0, 1.0, 1.0, 1.0],\n",
    "                                                     [1.0, 1.0, 1.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e22d94e1",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1622327690183,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "e22d94e1"
   },
   "outputs": [],
   "source": [
    "model.rpn.anchor_generator = anchor_generator\n",
    "model.rpn.head = RPNHead(256, anchor_generator.num_anchors_per_location()[0])\n",
    "# get the number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f07a68e",
   "metadata": {
    "executionInfo": {
     "elapsed": 2753,
     "status": "ok",
     "timestamp": 1622327692924,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "9f07a68e"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(PATH):\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204fb3d",
   "metadata": {
    "id": "f204fb3d"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11b85856",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465465,
     "status": "ok",
     "timestamp": 1622328158363,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "11b85856",
    "outputId": "cc2bf505-8be7-4d92-caf5-aa7aa37fa6f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/11]  eta: 0:01:04  lr: 0.000505  loss: 0.6529 (0.6529)  loss_classifier: 0.0254 (0.0254)  loss_box_reg: 0.0108 (0.0108)  loss_objectness: 0.0854 (0.0854)  loss_rpn_box_reg: 0.5313 (0.5313)  time: 5.8782  data: 2.0336  max mem: 3747\n",
      "Epoch: [0]  [ 1/11]  eta: 0:00:35  lr: 0.001004  loss: 0.4463 (0.5496)  loss_classifier: 0.0254 (0.0325)  loss_box_reg: 0.0108 (0.0198)  loss_objectness: 0.0701 (0.0778)  loss_rpn_box_reg: 0.3079 (0.4196)  time: 3.5635  data: 1.2454  max mem: 4011\n",
      "Epoch: [0]  [ 2/11]  eta: 0:00:24  lr: 0.001503  loss: 0.4463 (0.5043)  loss_classifier: 0.0395 (0.0361)  loss_box_reg: 0.0289 (0.0231)  loss_objectness: 0.0784 (0.0780)  loss_rpn_box_reg: 0.3079 (0.3671)  time: 2.7759  data: 0.9492  max mem: 4011\n",
      "Epoch: [0]  [ 3/11]  eta: 0:00:18  lr: 0.002003  loss: 0.4423 (0.4888)  loss_classifier: 0.0346 (0.0357)  loss_box_reg: 0.0231 (0.0231)  loss_objectness: 0.0701 (0.0735)  loss_rpn_box_reg: 0.3079 (0.3564)  time: 2.3568  data: 0.8196  max mem: 4011\n",
      "Epoch: [0]  [ 4/11]  eta: 0:00:14  lr: 0.002502  loss: 0.4463 (0.4852)  loss_classifier: 0.0346 (0.0330)  loss_box_reg: 0.0231 (0.0213)  loss_objectness: 0.0701 (0.0713)  loss_rpn_box_reg: 0.3244 (0.3597)  time: 2.1294  data: 0.7305  max mem: 4011\n",
      "Epoch: [0]  [ 5/11]  eta: 0:00:11  lr: 0.003002  loss: 0.4423 (0.4780)  loss_classifier: 0.0281 (0.0321)  loss_box_reg: 0.0204 (0.0211)  loss_objectness: 0.0628 (0.0699)  loss_rpn_box_reg: 0.3244 (0.3548)  time: 1.9500  data: 0.6495  max mem: 4011\n",
      "Epoch: [0]  [ 6/11]  eta: 0:00:09  lr: 0.003501  loss: 0.4463 (0.5004)  loss_classifier: 0.0345 (0.0325)  loss_box_reg: 0.0231 (0.0223)  loss_objectness: 0.0701 (0.0723)  loss_rpn_box_reg: 0.3306 (0.3733)  time: 1.8280  data: 0.5920  max mem: 4011\n",
      "Epoch: [0]  [ 7/11]  eta: 0:00:07  lr: 0.004001  loss: 0.4423 (0.4776)  loss_classifier: 0.0281 (0.0319)  loss_box_reg: 0.0204 (0.0220)  loss_objectness: 0.0628 (0.0692)  loss_rpn_box_reg: 0.3244 (0.3545)  time: 1.7526  data: 0.5696  max mem: 4011\n",
      "Epoch: [0]  [ 8/11]  eta: 0:00:05  lr: 0.004501  loss: 0.4463 (0.4835)  loss_classifier: 0.0281 (0.0305)  loss_box_reg: 0.0204 (0.0206)  loss_objectness: 0.0628 (0.0672)  loss_rpn_box_reg: 0.3306 (0.3653)  time: 1.6926  data: 0.5508  max mem: 4011\n",
      "Epoch: [0]  [ 9/11]  eta: 0:00:03  lr: 0.005000  loss: 0.4463 (0.4833)  loss_classifier: 0.0278 (0.0298)  loss_box_reg: 0.0196 (0.0196)  loss_objectness: 0.0623 (0.0644)  loss_rpn_box_reg: 0.3306 (0.3694)  time: 1.6832  data: 0.5733  max mem: 4011\n",
      "Epoch: [0]  [10/11]  eta: 0:00:01  lr: 0.005000  loss: 0.4709 (0.4888)  loss_classifier: 0.0281 (0.0298)  loss_box_reg: 0.0196 (0.0196)  loss_objectness: 0.0628 (0.0664)  loss_rpn_box_reg: 0.3728 (0.3730)  time: 1.6386  data: 0.5574  max mem: 4011\n",
      "Epoch: [0] Total time: 0:00:18 (1.6446 s / it)\n",
      "n_threads =  1\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:01  model_time: 0.1166 (0.1166)  evaluator_time: 0.0387 (0.0387)  time: 0.1871  data: 0.0305  max mem: 4011\n",
      "Test:  [5/6]  eta: 0:00:00  model_time: 0.0979 (0.1011)  evaluator_time: 0.0012 (0.0075)  time: 0.1373  data: 0.0269  max mem: 4011\n",
      "Test: Total time: 0:00:00 (0.1375 s / it)\n",
      "Averaged stats: model_time: 0.0979 (0.1011)  evaluator_time: 0.0012 (0.0075)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.370\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "Epoch: [1]  [ 0/11]  eta: 0:00:12  lr: 0.005000  loss: 0.5224 (0.5224)  loss_classifier: 0.0331 (0.0331)  loss_box_reg: 0.0260 (0.0260)  loss_objectness: 0.0481 (0.0481)  loss_rpn_box_reg: 0.4151 (0.4151)  time: 1.1608  data: 0.3091  max mem: 4011\n",
      "Epoch: [1]  [ 1/11]  eta: 0:00:11  lr: 0.005000  loss: 0.4574 (0.4899)  loss_classifier: 0.0282 (0.0307)  loss_box_reg: 0.0213 (0.0237)  loss_objectness: 0.0315 (0.0398)  loss_rpn_box_reg: 0.3764 (0.3957)  time: 1.1784  data: 0.3463  max mem: 4011\n",
      "Epoch: [1]  [ 2/11]  eta: 0:00:10  lr: 0.005000  loss: 0.4574 (0.4780)  loss_classifier: 0.0331 (0.0469)  loss_box_reg: 0.0260 (0.0338)  loss_objectness: 0.0481 (0.0466)  loss_rpn_box_reg: 0.3764 (0.3507)  time: 1.1828  data: 0.3544  max mem: 4011\n",
      "Epoch: [1]  [ 3/11]  eta: 0:00:09  lr: 0.005000  loss: 0.4541 (0.4599)  loss_classifier: 0.0310 (0.0429)  loss_box_reg: 0.0236 (0.0312)  loss_objectness: 0.0364 (0.0440)  loss_rpn_box_reg: 0.3147 (0.3417)  time: 1.1340  data: 0.3060  max mem: 4011\n",
      "Epoch: [1]  [ 4/11]  eta: 0:00:08  lr: 0.005000  loss: 0.4574 (0.4913)  loss_classifier: 0.0331 (0.0425)  loss_box_reg: 0.0260 (0.0304)  loss_objectness: 0.0481 (0.0497)  loss_rpn_box_reg: 0.3764 (0.3687)  time: 1.1554  data: 0.3340  max mem: 4011\n",
      "Epoch: [1]  [ 5/11]  eta: 0:00:06  lr: 0.005000  loss: 0.4574 (0.4965)  loss_classifier: 0.0314 (0.0406)  loss_box_reg: 0.0260 (0.0297)  loss_objectness: 0.0481 (0.0506)  loss_rpn_box_reg: 0.3764 (0.3756)  time: 1.1474  data: 0.3307  max mem: 4011\n",
      "Epoch: [1]  [ 6/11]  eta: 0:00:05  lr: 0.005000  loss: 0.4766 (0.4937)  loss_classifier: 0.0314 (0.0390)  loss_box_reg: 0.0260 (0.0284)  loss_objectness: 0.0481 (0.0500)  loss_rpn_box_reg: 0.3797 (0.3762)  time: 1.1348  data: 0.3200  max mem: 4011\n",
      "Epoch: [1]  [ 7/11]  eta: 0:00:04  lr: 0.005000  loss: 0.4766 (0.5047)  loss_classifier: 0.0314 (0.0382)  loss_box_reg: 0.0260 (0.0288)  loss_objectness: 0.0467 (0.0489)  loss_rpn_box_reg: 0.3797 (0.3889)  time: 1.1227  data: 0.3039  max mem: 4011\n",
      "Epoch: [1]  [ 8/11]  eta: 0:00:03  lr: 0.005000  loss: 0.5224 (0.5075)  loss_classifier: 0.0314 (0.0374)  loss_box_reg: 0.0260 (0.0284)  loss_objectness: 0.0481 (0.0506)  loss_rpn_box_reg: 0.4095 (0.3912)  time: 1.1086  data: 0.3036  max mem: 4011\n",
      "Epoch: [1]  [ 9/11]  eta: 0:00:02  lr: 0.005000  loss: 0.4766 (0.4999)  loss_classifier: 0.0310 (0.0359)  loss_box_reg: 0.0256 (0.0276)  loss_objectness: 0.0481 (0.0519)  loss_rpn_box_reg: 0.3797 (0.3845)  time: 1.1037  data: 0.2983  max mem: 4011\n",
      "Epoch: [1]  [10/11]  eta: 0:00:01  lr: 0.005000  loss: 0.4766 (0.4885)  loss_classifier: 0.0310 (0.0351)  loss_box_reg: 0.0256 (0.0272)  loss_objectness: 0.0548 (0.0530)  loss_rpn_box_reg: 0.3797 (0.3732)  time: 1.1072  data: 0.3028  max mem: 4012\n",
      "Epoch: [1] Total time: 0:00:12 (1.1080 s / it)\n",
      "n_threads =  1\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:00  model_time: 0.0958 (0.0958)  evaluator_time: 0.0010 (0.0010)  time: 0.1293  data: 0.0308  max mem: 4012\n",
      "Test:  [5/6]  eta: 0:00:00  model_time: 0.0976 (0.1028)  evaluator_time: 0.0010 (0.0012)  time: 0.1318  data: 0.0260  max mem: 4012\n",
      "Test: Total time: 0:00:00 (0.1320 s / it)\n",
      "Averaged stats: model_time: 0.0976 (0.1028)  evaluator_time: 0.0010 (0.0012)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2]  [ 0/11]  eta: 0:00:10  lr: 0.005000  loss: 0.3830 (0.3830)  loss_classifier: 0.0304 (0.0304)  loss_box_reg: 0.0287 (0.0287)  loss_objectness: 0.0373 (0.0373)  loss_rpn_box_reg: 0.2866 (0.2866)  time: 0.9938  data: 0.1802  max mem: 4012\n",
      "Epoch: [2]  [ 1/11]  eta: 0:00:09  lr: 0.005000  loss: 0.3830 (0.6319)  loss_classifier: 0.0304 (0.0508)  loss_box_reg: 0.0287 (0.0332)  loss_objectness: 0.0373 (0.0519)  loss_rpn_box_reg: 0.2866 (0.4960)  time: 0.9997  data: 0.1911  max mem: 4012\n",
      "Epoch: [2]  [ 2/11]  eta: 0:00:09  lr: 0.005000  loss: 0.5512 (0.6050)  loss_classifier: 0.0345 (0.0454)  loss_box_reg: 0.0303 (0.0323)  loss_objectness: 0.0399 (0.0479)  loss_rpn_box_reg: 0.4464 (0.4795)  time: 1.0497  data: 0.2445  max mem: 4012\n",
      "Epoch: [2]  [ 3/11]  eta: 0:00:08  lr: 0.005000  loss: 0.4955 (0.5776)  loss_classifier: 0.0304 (0.0389)  loss_box_reg: 0.0287 (0.0284)  loss_objectness: 0.0373 (0.0441)  loss_rpn_box_reg: 0.4262 (0.4662)  time: 1.0346  data: 0.2538  max mem: 4012\n",
      "Epoch: [2]  [ 4/11]  eta: 0:00:07  lr: 0.005000  loss: 0.4955 (0.5461)  loss_classifier: 0.0345 (0.0384)  loss_box_reg: 0.0287 (0.0284)  loss_objectness: 0.0373 (0.0416)  loss_rpn_box_reg: 0.4262 (0.4377)  time: 1.0771  data: 0.2865  max mem: 4012\n",
      "Epoch: [2]  [ 5/11]  eta: 0:00:06  lr: 0.005000  loss: 0.4587 (0.5315)  loss_classifier: 0.0345 (0.0409)  loss_box_reg: 0.0287 (0.0322)  loss_objectness: 0.0341 (0.0403)  loss_rpn_box_reg: 0.3240 (0.4181)  time: 1.0897  data: 0.2951  max mem: 4012\n",
      "Epoch: [2]  [ 6/11]  eta: 0:00:05  lr: 0.005000  loss: 0.4955 (0.5320)  loss_classifier: 0.0361 (0.0420)  loss_box_reg: 0.0303 (0.0326)  loss_objectness: 0.0361 (0.0397)  loss_rpn_box_reg: 0.4149 (0.4177)  time: 1.0853  data: 0.2868  max mem: 4012\n",
      "Epoch: [2]  [ 7/11]  eta: 0:00:04  lr: 0.005000  loss: 0.4955 (0.5768)  loss_classifier: 0.0345 (0.0410)  loss_box_reg: 0.0303 (0.0325)  loss_objectness: 0.0361 (0.0501)  loss_rpn_box_reg: 0.4149 (0.4532)  time: 1.0777  data: 0.2797  max mem: 4012\n",
      "Epoch: [2]  [ 8/11]  eta: 0:00:03  lr: 0.005000  loss: 0.4955 (0.5677)  loss_classifier: 0.0345 (0.0392)  loss_box_reg: 0.0303 (0.0311)  loss_objectness: 0.0361 (0.0472)  loss_rpn_box_reg: 0.4261 (0.4502)  time: 1.0758  data: 0.2866  max mem: 4012\n",
      "Epoch: [2]  [ 9/11]  eta: 0:00:02  lr: 0.005000  loss: 0.4948 (0.5541)  loss_classifier: 0.0341 (0.0380)  loss_box_reg: 0.0287 (0.0301)  loss_objectness: 0.0341 (0.0459)  loss_rpn_box_reg: 0.4149 (0.4401)  time: 1.0708  data: 0.2792  max mem: 4012\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-612cf1d172be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sample_projs/FRCNN/delivered/FastRCNN_Traffic/utilities/train_eval/engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_lr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sample_projs/FRCNN/delivered/FastRCNN_Traffic/utilities/utils.py\u001b[0m in \u001b[0;36mlog_every\u001b[0;34m(self, iterable, print_freq, header)\u001b[0m\n\u001b[1;32m    208\u001b[0m             ])\n\u001b[1;32m    209\u001b[0m         \u001b[0mMB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3.6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3.6/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sample_projs/FRCNN/delivered/FastRCNN_Traffic/utilities/data_utils/Dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sample_projs/FRCNN/delivered/FastRCNN_Traffic/utilities/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, image, target)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sample_projs/FRCNN/delivered/FastRCNN_Traffic/utilities/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, image, target)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv3.6/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# yikes, this transpose takes 80% of the loading time/CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    #res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
    "    #print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')\n",
    "\n",
    "    train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=1)\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dacacec0",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1622328158365,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "dacacec0"
   },
   "outputs": [],
   "source": [
    "# create output directory\n",
    "# if output directory exists, delete existing files\n",
    "if not os.path.exists(output_image_folder):\n",
    "    os.mkdir(output_image_folder)\n",
    "else:\n",
    "    files = glob.glob(output_image_folder + '/*')\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e5405",
   "metadata": {
    "id": "d56e5405"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce80527",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1622328159462,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "dce80527",
    "outputId": "aa240d6a-6bfc-4620-8b00-b1d85b7a4600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_threads =  1\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:00  model_time: 0.1013 (0.1013)  evaluator_time: 0.0013 (0.0013)  time: 0.1320  data: 0.0280  max mem: 4012\n",
      "Test:  [5/6]  eta: 0:00:00  model_time: 0.1030 (0.1066)  evaluator_time: 0.0013 (0.0013)  time: 0.1354  data: 0.0261  max mem: 4012\n",
      "Test: Total time: 0:00:00 (0.1356 s / it)\n",
      "Averaged stats: model_time: 0.1030 (0.1066)  evaluator_time: 0.0013 (0.0013)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.572\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.136\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.355\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.500\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utilities.coco_utils.coco_eval.CocoEvaluator at 0x7fc48de3fac8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eec1bdd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1622328159464,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "eec1bdd2",
    "outputId": "600f69a6-85ed-4a77-d701-0464ab58ea4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model saving complete!\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "# create directory for saving the model\n",
    "print(\"Saving model...\")\n",
    "torch.save(model.state_dict(), PATH)\n",
    "print(\"Model saving complete!\")\n",
    "nvidia_smi.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43035d27",
   "metadata": {
    "id": "43035d27"
   },
   "source": [
    "## Inference \n",
    "Repeating all the process to ensure nothing is taken from training stage\n",
    "Check output folder for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "758d7831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3965,
     "status": "ok",
     "timestamp": 1622328207520,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "758d7831",
    "outputId": "73219574-b751-42e4-bbe6-77b8b1e45db3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 8505131008\n",
      "Free memory: 6600261632\n",
      "Used memory: 1904869376\n",
      "initial boxes: ['warning', 'mandatory', 'mandatory', 'prohibitory', 'prohibitory', 'warning']\n",
      "initial boxes: ['warning', 'mandatory', 'mandatory', 'prohibitory', 'warning', 'prohibitory']\n",
      "initial boxes: ['mandatory', 'warning', 'prohibitory', 'mandatory', 'mandatory', 'prohibitory', 'warning']\n",
      "initial boxes: ['mandatory', 'mandatory', 'mandatory', 'warning', 'warning', 'prohibitory', 'warning', 'prohibitory', 'mandatory', 'prohibitory', 'warning', 'mandatory', 'mandatory', 'prohibitory', 'mandatory', 'mandatory', 'warning', 'warning', 'warning']\n",
      "initial boxes: ['warning', 'mandatory', 'prohibitory']\n",
      "initial boxes: ['mandatory', 'warning', 'prohibitory', 'warning', 'prohibitory', 'mandatory', 'warning', 'mandatory', 'prohibitory', 'mandatory', 'warning']\n",
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "print(\"Total memory:\", info.total)\n",
    "print(\"Free memory:\", info.free)\n",
    "print(\"Used memory:\", info.used)\n",
    "\n",
    "dataset_test = FacialDataset(root+'/data/test', get_transform(horizontal_flip=False),classes=classes)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=0,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "anchor_generator = AnchorGenerator(sizes=((32,), (24, ), (24, ), (16,), (8, )),\n",
    "                                   aspect_ratios=([1.0, 1.0, 1.0, 1.0],\n",
    "                                                  [0.8, 1.0, 1.0, 1.0],\n",
    "                                                  [1.0, 0.8, 1.0, 1.0],\n",
    "                                                  [1.0, 1.0, 1.0, 1.0],\n",
    "                                                  [1.0, 1.0, 1.0, 1.0]))\n",
    "model.rpn.anchor_generator = anchor_generator\n",
    "model.rpn.head = RPNHead(256, anchor_generator.num_anchors_per_location()[0])\n",
    "# get the number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "\n",
    "# create output directory\n",
    "# if output directory exists, delete existing files\n",
    "if not os.path.exists(output_image_folder):\n",
    "    os.mkdir(output_image_folder)\n",
    "else:\n",
    "    files = glob.glob(output_image_folder + '/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "# write testing result to output folder\n",
    "for img_idx, batch_sampler in enumerate(data_loader_test):\n",
    "    img_test = batch_sampler[0][0]\n",
    "    target_test = batch_sampler[1][0]\n",
    "    i = target_test[\"image_id\"].item()\n",
    "    get_model_result(img_test, model, target_test, i, device, location=output_image_folder, threshold=0.2,classes=classes)\n",
    "\n",
    "print(\"Testing complete!\")\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "nvidia_smi.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PrR48V6CTBO_",
   "metadata": {
    "id": "PrR48V6CTBO_"
   },
   "source": [
    "Check output folder to see the result images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea2757",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1622328160212,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "53ea2757"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104e90c",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1622328160213,
     "user": {
      "displayName": "jerin antony",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi8SQoJ-W8EWVxGgJHldI9GtDVtiGf2Le9C7J37lg=s64",
      "userId": "04607704621251550841"
     },
     "user_tz": -330
    },
    "id": "0104e90c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of FRCNN.ipynb",
   "provenance": [
    {
     "file_id": "14Z3aIGqmGYL_ouDChEinKEcydzTwuVVe",
     "timestamp": 1622328432652
    }
   ]
  },
  "kernelspec": {
   "display_name": "venv3.6",
   "language": "python",
   "name": "venv3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01e13365ef294ce9a03782c21bdab977": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fae98b5c8a204731924b2f86a0ced1d8",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d3963cb37194a538f667c2912fc5e50",
      "value": 167502836
     }
    },
    "1da9449b11624a5e847d8f9db04a1be2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54d6b5110a954b31977d857a5ce90e68",
      "placeholder": "",
      "style": "IPY_MODEL_9148ee255b104e6791272c05c250f5f5",
      "value": " 160M/160M [00:05&lt;00:00, 29.5MB/s]"
     }
    },
    "1f070ccd6e734de2b967233201ba264f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01e13365ef294ce9a03782c21bdab977",
       "IPY_MODEL_1da9449b11624a5e847d8f9db04a1be2"
      ],
      "layout": "IPY_MODEL_39f0d703e45740abb4808269b3c3da1a"
     }
    },
    "39f0d703e45740abb4808269b3c3da1a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54d6b5110a954b31977d857a5ce90e68": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9148ee255b104e6791272c05c250f5f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d3963cb37194a538f667c2912fc5e50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fae98b5c8a204731924b2f86a0ced1d8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
