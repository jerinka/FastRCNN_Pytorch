{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1663198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aniso8601==8.1.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (8.1.0)\n",
      "Requirement already satisfied: ansi2html==1.6.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: arrow==0.17.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: asttokens==2.0.4 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: attrs==20.3.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (20.3.0)\n",
      "Requirement already satisfied: certifi==2020.12.5 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (2020.12.5)\n",
      "Requirement already satisfied: chardet==4.0.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: click==7.1.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (7.1.2)\n",
      "Requirement already satisfied: cycler==0.10.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (0.10.0)\n",
      "Requirement already satisfied: Cython==0.29.21 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (0.29.21)\n",
      "Requirement already satisfied: executing==0.5.4 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 11)) (0.5.4)\n",
      "Requirement already satisfied: Flask==1.1.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (1.1.2)\n",
      "Requirement already satisfied: Flask-RESTful==0.3.8 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (0.3.8)\n",
      "Requirement already satisfied: idna==2.10 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 14)) (2.10)\n",
      "Requirement already satisfied: importlib-metadata==3.3.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 15)) (3.3.0)\n",
      "Requirement already satisfied: iniconfig==1.1.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 16)) (1.1.1)\n",
      "Requirement already satisfied: itsdangerous==1.1.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 17)) (1.1.0)\n",
      "Requirement already satisfied: Jinja2==2.11.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 18)) (2.11.2)\n",
      "Requirement already satisfied: kiwisolver==1.3.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 19)) (1.3.1)\n",
      "Requirement already satisfied: littleutils==0.2.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 20)) (0.2.2)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 21)) (1.1.1)\n",
      "Requirement already satisfied: matplotlib==3.3.3 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 22)) (3.3.3)\n",
      "Requirement already satisfied: numpy in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 23)) (1.19.5)\n",
      "Requirement already satisfied: nvidia-ml-py3==7.352.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 24)) (7.352.0)\n",
      "Requirement already satisfied: olefile==0.46 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 25)) (0.46)\n",
      "Requirement already satisfied: packaging==20.8 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 26)) (20.8)\n",
      "Requirement already satisfied: pandas in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 27)) (1.1.5)\n",
      "Requirement already satisfied: Pillow in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 28)) (8.1.2)\n",
      "Requirement already satisfied: pluggy==0.13.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 29)) (0.13.1)\n",
      "Requirement already satisfied: psutil==5.8.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 30)) (5.8.0)\n",
      "Requirement already satisfied: py==1.10.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 31)) (1.10.0)\n",
      "Requirement already satisfied: pycocotools==2.0.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 32)) (2.0.2)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 33)) (2.4.7)\n",
      "Requirement already satisfied: pytest==6.2.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 34)) (6.2.1)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 35)) (2.8.1)\n",
      "Requirement already satisfied: pytz==2020.5 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 36)) (2020.5)\n",
      "Requirement already satisfied: requests==2.25.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 37)) (2.25.1)\n",
      "Requirement already satisfied: six in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 38)) (1.15.0)\n",
      "Requirement already satisfied: sorcery==0.2.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 39)) (0.2.1)\n",
      "Requirement already satisfied: tabulate==0.8.7 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 40)) (0.8.7)\n",
      "Requirement already satisfied: termcolor==1.1.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 41)) (1.1.0)\n",
      "Requirement already satisfied: toml==0.10.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 42)) (0.10.2)\n",
      "Requirement already satisfied: torch==1.4.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 43)) (1.4.0)\n",
      "Requirement already satisfied: torchaudio in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 44)) (0.4.0)\n",
      "Requirement already satisfied: torchvision==0.5.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 45)) (0.5.0)\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 46)) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3==1.26.2 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 47)) (1.26.2)\n",
      "Requirement already satisfied: Werkzeug==1.0.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 48)) (1.0.1)\n",
      "Requirement already satisfied: wrapt==1.12.1 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 49)) (1.12.1)\n",
      "Requirement already satisfied: xmltodict==0.12.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 50)) (0.12.0)\n",
      "Requirement already satisfied: zipp==3.4.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from -r requirements.txt (line 51)) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in /home/skycam/venv3.6/lib/python3.6/site-packages (from pycocotools==2.0.2->-r requirements.txt (line 32)) (54.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362e2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utilities.data_utils.Dataset import FacialDataset, get_transform\n",
    "from utilities.utils import collate_fn\n",
    "from utilities.train_eval.engine import train_one_epoch, evaluate, get_model_result\n",
    "import glob\n",
    "\n",
    "import nvidia_smi # for python 3, you need nvidia-ml-py3 library\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c31b021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'Weight.pth'\n",
    "\n",
    "output_image_folder = 'output'\n",
    "\n",
    "proj = 'sign' # 'sign','fabric' (put ur project name here)\n",
    "\n",
    "if proj == 'sign':\n",
    "    classes = ['warning', 'prohibitory', 'mandatory']\n",
    "elif proj == 'fabric':\n",
    "    classes = ['Hole', 'Line', 'Stain']\n",
    "else:\n",
    "    classes = ['bg']\n",
    "\n",
    "num_classes = len(classes)+1  # n class + background\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63ec7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 8505131008\n",
      "Free memory: 8067940352\n",
      "Used memory: 437190656\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "print(\"Total memory:\", info.total)\n",
    "print(\"Free memory:\", info.free)\n",
    "print(\"Used memory:\", info.used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44b9243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = FacialDataset('data/train', get_transform(horizontal_flip=True),classes=classes)\n",
    "dataset_test = FacialDataset('data/test', get_transform(horizontal_flip=False),classes=classes)\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0,\n",
    "        collate_fn=collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=0,\n",
    "    collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88219df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a20d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_generator = AnchorGenerator(sizes=((32,), (24, ), (24, ), (16,), (8, )),\n",
    "                                        aspect_ratios=([1.0, 1.0, 1.0, 1.0], \n",
    "                                                     [0.8, 1.0, 1.0, 1.0], \n",
    "                                                     [1.0, 0.8, 1.0, 1.0],\n",
    "                                                     [1.0, 1.0, 1.0, 1.0],\n",
    "                                                     [1.0, 1.0, 1.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22d94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rpn.anchor_generator = anchor_generator\n",
    "model.rpn.head = RPNHead(256, anchor_generator.num_anchors_per_location()[0])\n",
    "# get the number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f07a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(PATH):\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204fb3d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b85856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 33%, gpu-mem: 3%\n",
      "Epoch: [0]  [ 0/11]  eta: 0:00:12  lr: 0.000505  loss: 2.2714 (2.2714)  loss_classifier: 0.0256 (0.0256)  loss_box_reg: 0.0066 (0.0066)  loss_objectness: 0.5678 (0.5678)  loss_rpn_box_reg: 1.6715 (1.6715)  time: 1.1364  data: 0.1602  max mem: 3745\n",
      "Epoch: [0]  [ 1/11]  eta: 0:00:11  lr: 0.001004  loss: 1.6878 (1.9796)  loss_classifier: 0.0256 (0.0629)  loss_box_reg: 0.0066 (0.0204)  loss_objectness: 0.5547 (0.5612)  loss_rpn_box_reg: 0.9987 (1.3351)  time: 1.1069  data: 0.2103  max mem: 4015\n",
      "Epoch: [0]  [ 2/11]  eta: 0:00:10  lr: 0.001503  loss: 2.2714 (2.1540)  loss_classifier: 0.0256 (0.0495)  loss_box_reg: 0.0066 (0.0143)  loss_objectness: 0.5678 (0.5885)  loss_rpn_box_reg: 1.6715 (1.5017)  time: 1.1658  data: 0.3053  max mem: 4015\n",
      "Epoch: [0]  [ 3/11]  eta: 0:00:09  lr: 0.002003  loss: 2.2714 (2.2578)  loss_classifier: 0.0228 (0.0401)  loss_box_reg: 0.0022 (0.0108)  loss_objectness: 0.5678 (0.5841)  loss_rpn_box_reg: 1.6715 (1.6227)  time: 1.1942  data: 0.3394  max mem: 4015\n",
      "Epoch: [0]  [ 4/11]  eta: 0:00:08  lr: 0.002502  loss: 2.2714 (2.0686)  loss_classifier: 0.0256 (0.0601)  loss_box_reg: 0.0066 (0.0219)  loss_objectness: 0.5678 (0.5675)  loss_rpn_box_reg: 1.6715 (1.4190)  time: 1.2081  data: 0.3652  max mem: 4015\n",
      "Epoch: [0]  [ 5/11]  eta: 0:00:07  lr: 0.003002  loss: 1.6878 (1.9199)  loss_classifier: 0.0256 (0.0609)  loss_box_reg: 0.0066 (0.0234)  loss_objectness: 0.5547 (0.5546)  loss_rpn_box_reg: 0.9987 (1.2809)  time: 1.1979  data: 0.3625  max mem: 4015\n",
      "Epoch: [0]  [ 6/11]  eta: 0:00:05  lr: 0.003501  loss: 1.6878 (1.8734)  loss_classifier: 0.0391 (0.0578)  loss_box_reg: 0.0130 (0.0219)  loss_objectness: 0.5547 (0.5514)  loss_rpn_box_reg: 1.0101 (1.2422)  time: 1.1854  data: 0.3495  max mem: 4015\n",
      "Epoch: [0]  [ 7/11]  eta: 0:00:04  lr: 0.004001  loss: 1.5941 (1.8309)  loss_classifier: 0.0388 (0.0554)  loss_box_reg: 0.0130 (0.0213)  loss_objectness: 0.5407 (0.5501)  loss_rpn_box_reg: 0.9987 (1.2042)  time: 1.1632  data: 0.3308  max mem: 4015\n",
      "Epoch: [0]  [ 8/11]  eta: 0:00:03  lr: 0.004501  loss: 1.5941 (1.7855)  loss_classifier: 0.0388 (0.0524)  loss_box_reg: 0.0130 (0.0198)  loss_objectness: 0.5547 (0.5541)  loss_rpn_box_reg: 0.9987 (1.1591)  time: 1.1634  data: 0.3277  max mem: 4015\n",
      "Epoch: [0]  [ 9/11]  eta: 0:00:02  lr: 0.005000  loss: 1.5424 (1.7612)  loss_classifier: 0.0388 (0.0544)  loss_box_reg: 0.0130 (0.0204)  loss_objectness: 0.5407 (0.5478)  loss_rpn_box_reg: 0.9537 (1.1385)  time: 1.1657  data: 0.3311  max mem: 4015\n",
      "Epoch: [0]  [10/11]  eta: 0:00:01  lr: 0.005000  loss: 1.5941 (1.7529)  loss_classifier: 0.0391 (0.0542)  loss_box_reg: 0.0165 (0.0202)  loss_objectness: 0.5547 (0.5528)  loss_rpn_box_reg: 0.9981 (1.1258)  time: 1.1433  data: 0.3084  max mem: 4015\n",
      "Epoch: [0] Total time: 0:00:12 (1.1443 s / it)\n",
      "n_threads =  1\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:00  model_time: 0.0992 (0.0992)  evaluator_time: 0.0005 (0.0005)  time: 0.1325  data: 0.0310  max mem: 4015\n",
      "Test:  [5/6]  eta: 0:00:00  model_time: 0.0992 (0.1003)  evaluator_time: 0.0008 (0.0007)  time: 0.1299  data: 0.0274  max mem: 4015\n",
      "Test: Total time: 0:00:00 (0.1300 s / it)\n",
      "Averaged stats: model_time: 0.0992 (0.1003)  evaluator_time: 0.0008 (0.0007)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
    "    print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')\n",
    "\n",
    "    train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=10)\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dacacec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output directory\n",
    "# if output directory exists, delete existing files\n",
    "if not os.path.exists(output_image_folder):\n",
    "    os.mkdir(output_image_folder)\n",
    "else:\n",
    "    files = glob.glob(output_image_folder + '/*')\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e5405",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce80527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_threads =  1\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/6]  eta: 0:00:00  model_time: 0.0972 (0.0972)  evaluator_time: 0.0005 (0.0005)  time: 0.1308  data: 0.0316  max mem: 4015\n",
      "Test:  [5/6]  eta: 0:00:00  model_time: 0.1005 (0.1044)  evaluator_time: 0.0008 (0.0008)  time: 0.1346  data: 0.0274  max mem: 4015\n",
      "Test: Total time: 0:00:00 (0.1347 s / it)\n",
      "Averaged stats: model_time: 0.1005 (0.1044)  evaluator_time: 0.0008 (0.0008)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utilities.coco_utils.coco_eval.CocoEvaluator at 0x7f4778f8dcc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec1bdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model saving complete!\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.synchronize()\n",
    "# create directory for saving the model\n",
    "print(\"Saving model...\")\n",
    "torch.save(model.state_dict(), PATH)\n",
    "print(\"Model saving complete!\")\n",
    "nvidia_smi.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43035d27",
   "metadata": {},
   "source": [
    "## Inference \n",
    "Repeating all the process to ensure nothing is taken from training stage\n",
    "Check output folder for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "758d7831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 8505131008\n",
      "Free memory: 6595018752\n",
      "Used memory: 1910112256\n",
      "initial boxes: []\n",
      "No prediction for 0\n",
      "initial boxes: ['mandatory']\n",
      "initial boxes: ['mandatory']\n",
      "initial boxes: ['mandatory', 'warning']\n",
      "initial boxes: ['mandatory', 'warning']\n",
      "initial boxes: ['mandatory']\n",
      "Testing complete!\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "print(\"Total memory:\", info.total)\n",
    "print(\"Free memory:\", info.free)\n",
    "print(\"Used memory:\", info.used)\n",
    "\n",
    "dataset_test = FacialDataset('data/test', get_transform(horizontal_flip=False),classes=classes)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=0,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "anchor_generator = AnchorGenerator(sizes=((32,), (24, ), (24, ), (16,), (8, )),\n",
    "                                   aspect_ratios=([1.0, 1.0, 1.0, 1.0],\n",
    "                                                  [0.8, 1.0, 1.0, 1.0],\n",
    "                                                  [1.0, 0.8, 1.0, 1.0],\n",
    "                                                  [1.0, 1.0, 1.0, 1.0],\n",
    "                                                  [1.0, 1.0, 1.0, 1.0]))\n",
    "model.rpn.anchor_generator = anchor_generator\n",
    "model.rpn.head = RPNHead(256, anchor_generator.num_anchors_per_location()[0])\n",
    "# get the number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "\n",
    "# create output directory\n",
    "# if output directory exists, delete existing files\n",
    "if not os.path.exists(output_image_folder):\n",
    "    os.mkdir(output_image_folder)\n",
    "else:\n",
    "    files = glob.glob(output_image_folder + '/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "# write testing result to output folder\n",
    "for img_idx, batch_sampler in enumerate(data_loader_test):\n",
    "    img_test = batch_sampler[0][0]\n",
    "    target_test = batch_sampler[1][0]\n",
    "    i = target_test[\"image_id\"].item()\n",
    "    get_model_result(img_test, model, target_test, i, device, location=output_image_folder, threshold=0.15,classes=classes)\n",
    "\n",
    "print(\"Testing complete!\")\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "nvidia_smi.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f56df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.6",
   "language": "python",
   "name": "venv3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
